20260223 작업 일지 #1 - 벤치마크 실행 준비 (버그 수정, Resume 기능, Colab 최적화)
================================================================================

1. 작업 목표
--------------------------------------------------------------------------------
작업 일지 #3(20260221_3)에서 구현한 벤치마크 실험 코드를 Colab에서 실행하기
위한 사전 준비 작업을 수행한다.

  - 코드 정적 분석 중 발견된 버그 3건 수정
  - Colab T4 GPU 환경에 맞춘 설정 조정
  - --resume 기능 구현 (완료된 run 재학습 방지, 중단된 학습 재개)
  - Baseline-only 실행 전략 수립 (CASDA 데이터 미생성 상태)
  - 실행 명령어 준비


2. 변경 파일
================================================================================

  | 파일                              | 상태 | 라인  | 변경 내용                                    |
  |-----------------------------------|------|-------|----------------------------------------------|
  | scripts/run_benchmark.py          | 수정 | 548   | 버그 3건 + --resume 기능 + skip/재개 로직    |
  | src/training/trainer.py           | 수정 | 428   | resume_from 매개변수 + 체크포인트 로드 로직  |
  | configs/benchmark_experiment.yaml | 수정 | 197   | num_workers 4→2 (Colab 호환)                 |


3. 핵심 기능: --resume (재학습 방지)
================================================================================

3.1 문제
---------
기존 코드는 실행할 때마다 timestamp 기반 새 디렉토리를 생성하고
모든 model×group 조합을 처음부터 학습한다.

  experiment_dir = output_dir / datetime.now().strftime("%Y%m%d_%H%M%S")

따라서:
  (1) baseline 6 runs를 완료한 뒤 CASDA 6 runs를 추가하면 baseline을 또 학습함
  (2) 학습 도중 Colab 세션이 끊기면 처음부터 재시작해야 함

3.2 해결: --resume 옵션
------------------------
  python scripts/run_benchmark.py \
      --config configs/benchmark_experiment.yaml \
      --resume outputs/benchmark_results/20260223_143000

  동작:
  (1) 기존 experiment_dir을 그대로 재사용 (새 timestamp 디렉토리 생성 안 함)
  (2) 각 model+group 조합에 대해 best.pth + experiment_meta.json 존재 여부 확인
  (3) 둘 다 존재 → SKIP: 기존 메트릭을 JSON에서 로드하여 reporter에 전달
  (4) latest.pth만 존재 → RESUME: 중단 지점부터 학습 재개
  (5) 둘 다 없음 → 새로 학습

3.3 변경 위치: scripts/run_benchmark.py
-----------------------------------------

  CLI 옵션 (370~373번 줄):
    parser.add_argument('--resume', type=str, default=None,
                        help='Resume from existing experiment directory.')

  experiment_dir 생성 로직 (401~410번 줄):
    if args.resume:
        experiment_dir = Path(args.resume)
        if not experiment_dir.exists():
            sys.exit(1)
    else:
        # 기존 timestamp 생성 로직

  run_single_experiment() 함수 (91~150번 줄):
    - resume 매개변수 추가 (기본값 False)
    - 완료 확인: best_path.exists() and meta_path.exists() → JSON에서 메트릭 로드, return
    - 중단 확인: latest_path.exists() and not best_path.exists() → resume_checkpoint 설정
    - resume_checkpoint를 BenchmarkTrainer에 resume_from으로 전달

  main() 호출부 (504번 줄):
    resume=bool(args.resume) 전달

3.4 변경 위치: src/training/trainer.py
---------------------------------------

  __init__() 매개변수 추가 (89번 줄):
    resume_from: Optional[str] = None

  _load_checkpoint() 메서드 신규 (190~210번 줄):
    - model_state_dict, optimizer_state_dict 복원
    - start_epoch = checkpoint['epoch'] + 1
    - history 복원
    - scheduler를 start_epoch까지 advance

  train() 메서드 수정 (352번 줄):
    - for epoch in range(self.start_epoch, self.epochs)
    - best_metric = self.history.get('best_metric', 0.0) (0.0 대신 복원값 사용)


4. 버그 수정 상세
================================================================================

4.1 typing import 위치 오류 (Critical)
---------------------------------------
  위치: scripts/run_benchmark.py
  증상: `from typing import Dict`가 파일 489번 줄(하단)에 위치
  영향: create_model() 함수 시그니처에서 `Dict` 타입 힌트 사용 →
        모듈 로드 시 NameError 발생 (Dict가 아직 import되지 않은 상태)
  수정: 36번 줄(상단 import 블록)으로 이동

4.2 FID 무조건 실행 오류 (Medium)
----------------------------------
  위치: scripts/run_benchmark.py, 474~482번 줄
  증상: FID 평가가 --groups 필터링과 무관하게 항상 실행됨
  영향: baseline_raw/baseline_trad만 실행할 때도 InceptionV3 로드 시도,
        CASDA 디렉토리가 존재하지 않으면 FileNotFoundError 발생
  수정: CASDA 그룹 포함 여부를 확인하는 조건문 추가

  변경 후 로직:
    casda_groups = {'casda_full', 'casda_pruning'}
    has_casda = any(g in casda_groups for g in group_keys)
    if args.fid_only or (has_casda and config...fid.compute):
        fid_results = run_fid_evaluation(...)
    elif not has_casda:
        logging.info("Skipping FID evaluation (no CASDA groups selected)")

4.3 --epochs CLI 옵션 누락 (Low)
----------------------------------
  위치: scripts/run_benchmark.py
  수정: `--epochs N` 옵션 추가, 지정 시 모든 모델의 epochs를 오버라이드
  용도: 빠른 검증 (예: --epochs 10)


5. 설정 변경
================================================================================

5.1 Colab num_workers 조정
---------------------------
  파일: configs/benchmark_experiment.yaml, 9번 줄
  변경: num_workers: 4 → 2
  근거: Colab T4 인스턴스는 vCPU 2개 제공, num_workers > 2는
        프로세스 경합으로 인한 성능 저하 또는 메모리 오류 발생 가능


6. 기타 발견 사항 (미수정)
================================================================================

6.1 CASDASyntheticDataset idx 미전달 (Low Priority)
----------------------------------------------------
  위치: src/training/dataset.py
  증상: _get_detection_item()과 _get_segmentation_item() 내부에서
        fallback 경로에 `idx` 변수를 사용하나, 메서드 매개변수로 전달되지 않음
  영향: 실제 도달 가능성 낮음 (try-except의 except 블록 내부)
  판단: CASDA 데이터 생성 후 해당 경로 테스트 시 수정 예정

6.2 train.csv 포맷 호환성 확인
-------------------------------
  실제 데이터: ImageId, ClassId 칼럼이 분리되어 있음 (ImageId_ClassId 결합 아님)
  코드 대응: dataset.py에서 두 가지 포맷을 조건문으로 분기 처리 → 호환 OK


7. Colab 실행 계획
================================================================================

7.1 심볼릭 링크 설정
--------------------
  Severstal 데이터가 Google Drive에 위치하므로, 프로젝트 루트에 심볼릭 링크 생성.
  YAML config의 상대 경로(train_images, train.csv)를 수정하지 않고 사용.

    cd /content/severstal-steel-defect-detection
    ln -sf /content/drive/MyDrive/data/Severstal/train_images train_images
    ln -sf /content/drive/MyDrive/data/Severstal/train.csv train.csv

7.2 테스트 실행 (YOLO-MFD, 10 epochs)
---------------------------------------
  단일 모델 × 단일 그룹으로 파이프라인 전체 동작 검증.

    python scripts/run_benchmark.py \
        --config configs/benchmark_experiment.yaml \
        --models yolo_mfd \
        --groups baseline_raw \
        --epochs 10

  확인 항목:
    - CSV 파싱 및 데이터 로드 정상 여부
    - 모델 생성 및 GPU 메모리 적합성
    - 학습 루프 (train → validate → checkpoint)
    - 메트릭 계산 (mAP@0.5)
    - 결과 저장 (JSON, 로그)

7.3 전체 Baseline 실행 (3 models × 2 groups, 100 epochs)
---------------------------------------------------------
  테스트 통과 후 baseline_raw + baseline_trad 그룹에 대해 전체 실행.

    python scripts/run_benchmark.py \
        --config configs/benchmark_experiment.yaml \
        --groups baseline_raw baseline_trad

  예상 소요: T4 GPU 기준 모델당 약 30~60분 × 6 runs = 3~6시간

7.4 이후 CASDA 그룹 추가 시 (--resume 활용)
--------------------------------------------
  CASDA 합성 이미지 생성 완료 후, 기존 baseline 결과 디렉토리에 추가 실행.
  baseline 6 runs는 자동 SKIP되고 CASDA 6 runs만 새로 학습.

    python scripts/run_benchmark.py \
        --config configs/benchmark_experiment.yaml \
        --resume outputs/benchmark_results/<baseline_실행_timestamp>

  이렇게 하면 12 runs 전체가 하나의 experiment_dir에 모이며,
  가설 검증(H1~H5) 시 baseline과 CASDA 결과를 직접 비교 가능.


8. 추가 변경: --data-dir / --csv CLI 옵션 및 경로 해석 수정
================================================================================

8.1 문제
---------
  Colab에서 실행 시, CWD(현재 작업 디렉토리)와 프로젝트 루트가 다를 수 있음.
  기존 코드는 config YAML의 상대 경로(예: "train_images", "train.csv")를
  CWD 기준으로 해석 → 경로 불일치 시 FileNotFoundError 발생.

  또한 Google Drive의 실제 데이터 위치가 config에 하드코딩된 상대 경로와
  다를 수 있어, 절대 경로를 CLI에서 직접 지정할 수 있어야 함.

8.2 해결
---------
  (1) CLI 옵션 추가 (scripts/run_benchmark.py):
      --data-dir : 이미지 디렉토리 절대 경로 (config의 image_dir 오버라이드)
      --csv      : 어노테이션 CSV 절대 경로 (config의 annotation_csv 오버라이드)
      --output-dir : 출력 디렉토리 절대 경로 (config의 output_dir 오버라이드)

  (2) 경로 해석 로직 (src/training/dataset.py):
      project_root = Path(__file__).resolve().parents[2]
      - 절대 경로 → 그대로 사용
      - 상대 경로 → project_root 기준으로 resolve

  (3) run_fid_evaluation() 내부에서도 동일한 경로 오버라이드 적용

8.3 변경 위치 상세
-------------------

  scripts/run_benchmark.py:
    - CLI 옵션 추가: --data-dir, --csv, --output-dir (argparse)
    - main() 내 config 오버라이드 로직:
        if args.data_dir:
            config['dataset']['image_dir'] = args.data_dir
        if args.csv:
            config['dataset']['annotation_csv'] = args.csv
        if args.output_dir:
            config['output']['base_dir'] = args.output_dir
    - run_fid_evaluation()에서 image_dir 경로 해석 시 동일 로직 적용
    - epilog 및 examples 텍스트 업데이트

  src/training/dataset.py:
    - 모듈 상단에 project_root 정의
    - SteelDefectDataset.__init__(): annotation_csv, image_dir 경로 해석
    - CASDASyntheticDataset.__init__(): casda_dir 경로 해석
    - 디버그 로깅 제거 (임시 출력이었음)

8.4 변경 파일 테이블 (갱신)
----------------------------

  | 파일                              | 상태 | 라인  | 변경 내용                                                   |
  |-----------------------------------|------|-------|-------------------------------------------------------------|
  | scripts/run_benchmark.py          | 수정 | ~555  | Dict→dict, --resume, --epochs, --data-dir, --csv,           |
  |                                   |      |       | --output-dir, FID skip, 경로 해석, epilog 갱신              |
  | src/training/trainer.py           | 수정 | ~428  | resume_from 매개변수 + 체크포인트 로드 로직                 |
  | src/training/dataset.py           | 수정 | ~737  | project_root 경로 해석, 절대/상대 경로 분기,                |
  |                                   |      |       | 디버그 로깅 제거                                            |
  | configs/benchmark_experiment.yaml | 수정 | 197   | num_workers 4→2                                             |


9. Colab 실행 명령어 (갱신)
================================================================================

  심볼릭 링크 방식 대신, CLI 인자로 절대 경로를 직접 지정하는 방식으로 변경.
  (심볼릭 링크 방식도 여전히 사용 가능하나, CLI 인자 방식이 더 명시적.)

9.1 테스트 실행 (YOLO-MFD, 10 epochs)
--------------------------------------
    python /content/severstal-steel-defect-detection/scripts/run_benchmark.py \
        --config /content/severstal-steel-defect-detection/configs/benchmark_experiment.yaml \
        --data-dir /content/drive/MyDrive/data/Severstal/train_images \
        --csv /content/drive/MyDrive/data/Severstal/train.csv \
        --output-dir /content/drive/MyDrive/outputs/benchmark_results \
        --models yolo_mfd \
        --groups baseline_raw \
        --epochs 10

9.2 전체 Baseline 실행 (3 models × 2 groups, 100 epochs)
---------------------------------------------------------
    python /content/severstal-steel-defect-detection/scripts/run_benchmark.py \
        --config /content/severstal-steel-defect-detection/configs/benchmark_experiment.yaml \
        --data-dir /content/drive/MyDrive/data/Severstal/train_images \
        --csv /content/drive/MyDrive/data/Severstal/train.csv \
        --output-dir /content/drive/MyDrive/outputs/benchmark_results \
        --groups baseline_raw baseline_trad

9.3 이후 CASDA 그룹 추가 시 (--resume 활용)
--------------------------------------------
    python /content/severstal-steel-defect-detection/scripts/run_benchmark.py \
        --config /content/severstal-steel-defect-detection/configs/benchmark_experiment.yaml \
        --data-dir /content/drive/MyDrive/data/Severstal/train_images \
        --csv /content/drive/MyDrive/data/Severstal/train.csv \
        --resume /content/drive/MyDrive/outputs/benchmark_results/<baseline_timestamp>

  주의: --data-dir, --csv, --output-dir 경로는 사용자의 실제 Google Drive 구조에
  맞게 조정 필요. 위 경로는 예시.


10. 추가 변경: test_ids 저장 및 결과 파일 경량화
================================================================================

10.1 배경
---------
  벤치마크 실험의 4개 데이터셋 그룹(baseline_raw, baseline_trad, casda_full,
  casda_pruning)은 동일한 seed=42 기반 stratified split을 사용하므로
  test set이 동일하다. 이를 명시적으로 기록하여 사후 검증 가능하게 한다.
  또한 학습 완료 후 불필요한 대용량 파일을 정리하여 저장 공간을 절약한다.

10.2 변경 사항
---------------

  (A) dataset_split.json 저장 (run_benchmark.py)
      - create_data_loaders()가 split_info dict를 추가 반환
        (train_ids, val_ids, test_ids, split_config, 각 set 크기)
      - experiment_dir에 dataset_split.json으로 1회만 저장
        (이미 존재하면 재저장하지 않음)
      - 모든 run이 동일한 split을 사용함을 JSON으로 증명 가능

  (B) experiment_meta.json 경량화 (run_benchmark.py)
      - 기존: training_history 전체를 중복 저장 (에포크별 loss/metric 배열)
      - 변경: best_epoch, best_metric, total_epochs_trained만 요약 저장
      - training_history는 별도 {name}_history.json에만 존재 (중복 제거)

  (C) best.pth 경량화 (trainer.py)
      - 학습 완료 후 best.pth에서 optimizer_state_dict, history 제거
      - 추론에 필요한 model_state_dict, epoch, metrics만 유지
      - 예상 크기 절감: 모델에 따라 40~60% 감소

  (D) latest.pth 자동 삭제 (trainer.py)
      - latest.pth는 학습 중 resume 전용 체크포인트
      - 학습 정상 완료 후 자동 삭제 (os.remove)
      - 중단된 경우에만 latest.pth가 남아 --resume으로 활용 가능

10.3 변경 위치
---------------

  src/training/dataset.py:
    - create_data_loaders() 반환형: Tuple[..., DataLoader] → Tuple[..., DataLoader, dict]
    - 함수 끝에서 split_info dict 생성 및 반환

  scripts/run_benchmark.py:
    - create_data_loaders() 호출부: split_info 수신
    - dataset_split.json 저장 로직 추가
    - experiment_meta.json에서 training_history 제거, 요약 필드로 대체

  src/training/trainer.py:
    - train() 종료 시: best.pth slim down (optimizer 제거)
    - train() 종료 시: latest.pth 삭제

10.4 실험 출력 디렉토리 구조 (변경 후)
---------------------------------------

  experiment_dir/
    dataset_split.json                    ← NEW: test_ids 등 split 정보 (1회)
    yolo_mfd_baseline_raw/
      experiment_meta.json                ← 경량화 (history 제거)
      yolo_mfd_baseline_raw_history.json  ← 학습 이력 (기존과 동일)
      checkpoints/
        yolo_mfd_baseline_raw_best.pth    ← 경량화 (optimizer 제거)
                                             latest.pth는 학습 완료 시 삭제됨
      tensorboard/                        ← TensorBoard 로그
    yolo_mfd_baseline_trad/
      ...
    eb_yolov8_baseline_raw/
      ...


11. 추가 변경: 300 epoch 골든 스탠다드 + AMP + Early Stopping 기록
================================================================================

11.1 배경
---------
  데이터 증강(CASDA)의 효과를 객관적으로 입증하려면 모델의 성능을 충분히
  끌어낸 상태에서 비교해야 한다. 300 epoch를 학습 상한선으로 설정하고,
  Early Stopping 결과를 함께 제시하는 것이 골든 스탠다드 설정이다.
  AMP(Automatic Mixed Precision)를 적용하여 T4 GPU Tensor Core를 활용,
  학습 시간을 1.5~2배 단축한다.

11.2 YAML config 변경 (benchmark_experiment.yaml)
--------------------------------------------------

  | 모델          | 항목                     | 변경 전 | 변경 후 |
  |---------------|--------------------------|---------|---------|
  | YOLO-MFD      | epochs                   | 100     | 300     |
  |               | warmup_epochs            | 5       | 10      |
  |               | early_stopping_patience  | 15      | 30      |
  |               | use_amp                  | (없음)  | true    |
  | EB-YOLOv8     | epochs                   | 100     | 300     |
  |               | warmup_epochs            | 5       | 10      |
  |               | early_stopping_patience  | 15      | 30      |
  |               | use_amp                  | (없음)  | true    |
  | DeepLabV3+    | epochs                   | 100     | 300     |
  |               | warmup_epochs            | 3       | 5       |
  |               | early_stopping_patience  | 20      | 40      |
  |               | use_amp                  | (없음)  | true    |

  patience 근거: epoch 상한의 ~10%로 설정하여, 일시적 plateau에서
  조기 종료를 방지하면서도 수렴 후 불필요한 학습을 막음.

11.3 AMP 적용 (trainer.py)
---------------------------
  torch.cuda.amp.GradScaler + autocast 적용.

  변경 위치:
    __init__():
      - self.use_amp = config에서 읽음 (기본 True, CPU면 False)
      - self.scaler = GradScaler(enabled=self.use_amp)

    train_one_epoch():
      - forward pass: with autocast(enabled=self.use_amp)
      - backward: scaler.scale(loss).backward()
      - gradient clip: scaler.unscale_() 후 clip_grad_norm_
      - optimizer step: scaler.step() + scaler.update()

    validate():
      - inference: with autocast(enabled=self.use_amp)

    _save_checkpoint():
      - scaler_state_dict 저장 (resume 시 복원용)

    _load_checkpoint():
      - scaler_state_dict 복원

11.4 Early Stopping 기록 (trainer.py + run_benchmark.py)
---------------------------------------------------------
  trainer.py — train() 종료 시 history에 기록:
    - early_stopped: bool (early stopping 발생 여부)
    - stopped_epoch: 실제 학습 종료 에포크
    - max_epochs: 설정된 상한 (300)
    - total_time_seconds: 총 학습 시간 (초)
    - use_amp: AMP 사용 여부

  run_benchmark.py — experiment_meta.json에 추가 필드:
    - early_stopped, stopped_epoch, max_epochs
    - total_time_seconds, use_amp

  논문 제시 형태 예시:
    "YOLO-MFD: 300 epoch 상한, patience=30, 실제 187 epoch에서 수렴
     (early stopping), best mAP@0.5 = 0.XXX at epoch 152"

11.5 변경 파일 테이블 (갱신)
----------------------------

  | 파일                              | 상태 | 변경 내용                                    |
  |-----------------------------------|------|----------------------------------------------|
  | configs/benchmark_experiment.yaml | 수정 | epochs 300, patience 30/40, warmup 조정,     |
  |                                   |      | use_amp: true 추가                           |
  | src/training/trainer.py           | 수정 | AMP(GradScaler+autocast), early stop 기록,   |
  |                                   |      | scaler state 저장/복원                       |
  | scripts/run_benchmark.py          | 수정 | meta.json에 early stop + AMP 정보 추가       |


12. CASDA 데이터 패키징 스크립트 (package_casda_data.py)
================================================================================

12.1 목적
---------
  ControlNet v4 출력물을 CASDASyntheticDataset이 기대하는 벤치마크 형식으로 변환.

  입력:
    - augmented_images_v4/generated/*.png (생성 이미지 ~967장)
    - augmented_images_v4/generation_summary.json (메타데이터 + 품질 점수)
    - controlnet_dataset_v4/hints/*_hint.png (힌트 이미지, Red채널 = 결함 마스크)

  출력:
    - casda_full/images/, casda_full/masks/, casda_full/metadata.json
    - casda_pruning/images/, casda_pruning/masks/, casda_pruning/metadata.json
    - packaging_report.json (패키징 통계)

12.2 5가지 갭 해결 방법
-----------------------
  | 갭                          | 해결 방법                                       |
  |-----------------------------|------------------------------------------------|
  | metadata.json 부재          | generation_summary.json 파싱 → 생성             |
  | 마스크 부재                  | 힌트 Red채널 추출, threshold(>127) → 이진 마스크 |
  | suitability_score 부재       | quality_score를 그대로 사용                     |
  | 디렉토리 구조 불일치         | generated/ → images/, 마스크 → masks/           |
  | class_id 인코딩 (1-indexed) | 파일명에서 class{N} 파싱 → N-1 (0-indexed)      |

12.3 핵심 함수
--------------
  parse_class_id_from_filename(filename)
    - 정규식 _class(\d+)_ 로 추출, 1-indexed → 0-indexed 변환

  extract_mask_from_hint(hint_path, threshold=127)
    - OpenCV BGR 로드 → channel[2] (Red) 추출 → cv2.threshold → 이진 마스크

  build_quality_map(summary)
    - quality.sample_scores[] → {filename: quality_score} 매핑

  filename_to_sample_name(filename)
    - "xxx_gen0.png" → "xxx" (sample_name으로 역변환)

  package_data(...)
    - 메인 로직: 전체 처리 + casda_full 생성 + casda_pruning 필터링

12.4 pruning 로직
-----------------
  1. suitability_score >= threshold (기본 0.7) 필터
  2. score 내림차순 정렬
  3. top_k (기본 2000) 제한
  → ~967개 중 threshold 통과분만 casda_pruning에 포함

12.5 CLI 인수
-------------
  --generated-dir     생성 이미지 디렉토리
  --summary-json      generation_summary.json 경로
  --hint-dir          힌트 이미지 디렉토리
  --output-dir        출력 디렉토리 (casda_full/, casda_pruning/ 생성)
  --suitability-threshold  pruning 임계값 (기본: 0.7)
  --pruning-top-k     pruning 최대 개수 (기본: 2000)
  --mask-threshold    Red 채널 이진화 임계값 (기본: 127)

12.6 Colab 실행 예시
--------------------
  python scripts/package_casda_data.py \
      --generated-dir /content/drive/MyDrive/data/Severstal/augmented_images_v4/generated \
      --summary-json /content/drive/MyDrive/data/Severstal/augmented_images_v4/generation_summary.json \
      --hint-dir /content/drive/MyDrive/data/Severstal/controlnet_dataset_v4/hints \
      --output-dir /content/drive/MyDrive/data/Severstal/data/augmented

12.7 YAML config 주석 갱신
--------------------------
  - "5,000 synthetic images" → "~967 synthetic images (ControlNet v4)"
  - "top 2,000 by suitability" → "top-K by suitability (threshold >= 0.7)"
  - casda_full description: "all ~967 CASDA synthetic images"
  - casda_pruning description: "threshold >= 0.7"

12.8 변경 파일 테이블
---------------------
  | 파일                               | 상태 | 변경 내용                               |
  |------------------------------------|------|-----------------------------------------|
  | scripts/package_casda_data.py      | 신규 | ControlNet v4 출력 → 벤치마크 형식 변환  |
  | configs/benchmark_experiment.yaml  | 수정 | 이미지 수량 주석 갱신 (~967)            |


13. 문법 검증
================================================================================
  py_compile(scripts/run_benchmark.py)               → OK
  py_compile(src/training/dataset.py)                 → OK
  py_compile(src/training/trainer.py)                 → OK
  py_compile(scripts/package_casda_data.py)           → OK (ast.parse)
  yaml.safe_load(configs/benchmark_experiment.yaml)   → OK
