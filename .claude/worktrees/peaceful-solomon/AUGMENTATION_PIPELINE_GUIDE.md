# Context-Aware Steel Defect Augmentation (CASDA) Pipeline Guide

## Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Prerequisites](#prerequisites)
4. [Installation](#installation)
5. [Pipeline Execution](#pipeline-execution)
6. [Parameter Reference](#parameter-reference)
7. [Output Structure](#output-structure)
8. [Quality Control](#quality-control)
9. [Troubleshooting](#troubleshooting)
10. [Performance Benchmarks](#performance-benchmarks)
11. [Advanced Configuration](#advanced-configuration)

---

## Overview

The Context-Aware Steel Defect Augmentation (CASDA) pipeline generates realistic synthetic steel defect images using a trained ControlNet model. The system ensures physical plausibility by matching defect types with compatible background textures.

### Key Features
- **Physics-aware augmentation**: Defects only placed on compatible backgrounds
- **Controlled size variation**: 80-100% of original defect size (no enlargement)
- **Class-balanced generation**: Equal samples across 4 defect classes
- **Multi-stage quality validation**: Blur, artifact, and consistency checks
- **GPU-accelerated**: Fast generation with CUDA support
- **Seamless integration**: Direct CSV merge with original training data

### Target Metrics
- **Augmentation scale**: 20% of original dataset (~2,514 samples)
- **Per-class samples**: ~628-629 samples per class (4 classes total)
- **Quality threshold**: 0.7 (adjustable)
- **Expected pass rate**: 70-85% after validation

---

## Architecture

### 5-Phase Pipeline

```
┌──────────────────────────────────────────────────────────────┐
│  Phase 1: Background Extraction                              │
│  ├─ Extract clean 512x512 patches from defect-free regions  │
│  ├─ Classify by texture type (smooth, stripe, textured)     │
│  └─ Output: data/backgrounds/                               │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│  Phase 2: Defect Template Library                            │
│  ├─ Index existing ROI metadata by class & subtype          │
│  ├─ Compute background compatibility rules                  │
│  └─ Output: data/defect_templates/                          │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│  Phase 3: Augmented Data Generation (CORE)                   │
│  ├─ Load trained ControlNet model                           │
│  ├─ Sample compatible background-defect pairs               │
│  ├─ Generate synthetic masks with size variation            │
│  ├─ Create multi-channel hints (defect + edges + texture)   │
│  ├─ Run ControlNet inference                                │
│  └─ Output: data/augmented/                                 │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│  Phase 4: Quality Validation                                 │
│  ├─ Check blur (Laplacian variance)                         │
│  ├─ Detect artifacts (gradient analysis)                    │
│  ├─ Validate color consistency (LAB color space)            │
│  ├─ Verify defect metrics consistency                       │
│  └─ Output: data/augmented/validation/                      │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│  Phase 5: Dataset Merger                                     │
│  ├─ Convert augmented masks to RLE format                   │
│  ├─ Merge with original train.csv                           │
│  ├─ Generate statistics (original vs augmented)             │
│  └─ Output: data/final_dataset/train_augmented.csv          │
└──────────────────────────────────────────────────────────────┘
```

### Module Dependencies

The pipeline uses these existing modules (from previous development):
- `src/analysis/defect_characterization.py`: Defect metric analysis
- `src/analysis/background_characterization.py`: Background classification
- `src/analysis/roi_suitability.py`: Compatibility matching rules
- `src/preprocessing/hint_generator.py`: Multi-channel hint creation
- `src/preprocessing/prompt_generator.py`: Text prompt generation
- `src/utils/rle.py`: RLE encoding/decoding utilities

---

## Prerequisites

### Required Files

Before starting, ensure you have:

1. **Original Dataset**
   - `train.csv`: Original training labels with RLE-encoded masks
   - `train_images/`: Directory with ~12,568 training images (1600×256 pixels)

2. **ROI Metadata** (from previous pipeline)
   - `data/processed/roi_patches/roi_metadata.csv`
   - Generated by: `scripts/extract_rois.py`

3. **Trained ControlNet Model**
   - `outputs/controlnet_training/best.pth`
   - Generated by: `scripts/train_controlnet.py`

### System Requirements

**Hardware**:
- GPU: NVIDIA GPU with ≥8GB VRAM (recommended: RTX 3060 or better)
- RAM: ≥16GB
- Storage: ≥10GB free space for augmented data

**Software**:
- Python: 3.8+
- CUDA: 11.0+ (for GPU acceleration)
- Operating System: Windows/Linux/macOS

### Python Dependencies

```bash
pip install numpy pandas opencv-python scikit-image torch torchvision tqdm pillow
```

**Version requirements**:
- torch>=1.10.0 (with CUDA support)
- torchvision>=0.11.0
- opencv-python>=4.5.0
- scikit-image>=0.18.0
- numpy>=1.21.0
- pandas>=1.3.0

---

## Installation

### Step 1: Verify Project Structure

```bash
cd D:\project\severstal-steel-defect-detection
```

Expected structure:
```
severstal-steel-defect-detection/
├── train.csv
├── train_images/
├── scripts/
│   ├── extract_clean_backgrounds.py
│   ├── build_defect_templates.py
│   ├── generate_augmented_data.py
│   ├── validate_augmented_quality.py
│   └── merge_datasets.py
├── src/
│   ├── analysis/
│   ├── preprocessing/
│   └── utils/
└── data/
    └── processed/
        └── roi_patches/
            └── roi_metadata.csv
```

### Step 2: Verify Dependencies

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

Expected output:
```
PyTorch: 1.x.x
CUDA available: True
```

### Step 3: Check Prerequisites

Run the prerequisite checker (if created) or manually verify:

```bash
# Check train.csv exists
ls train.csv

# Check images directory
ls train_images/ | head -5

# Check ROI metadata
ls data/processed/roi_patches/roi_metadata.csv

# Check ControlNet model
ls outputs/controlnet_training/best.pth
```

---

## Pipeline Execution

### Quick Start (Full Pipeline)

Use the automated execution script:

```bash
python scripts/run_augmentation_pipeline.py \
    --train_csv train.csv \
    --image_dir train_images \
    --model_path outputs/controlnet_training/best.pth \
    --output_dir data \
    --num_samples 2500
```

### Manual Step-by-Step Execution

#### Phase 1: Extract Clean Backgrounds

```bash
python scripts/extract_clean_backgrounds.py \
    --train_csv train.csv \
    --image_dir train_images \
    --output_dir data/backgrounds \
    --patch_size 512 \
    --patches_per_image 5 \
    --min_quality 0.7 \
    --stride 256
```

**Expected duration**: 10-20 minutes
**Expected output**: ~3,000-5,000 background patches

**Verification**:
```bash
ls data/backgrounds/
# Should see: smooth/, vertical_stripe/, horizontal_stripe/, textured/, complex_pattern/

python -c "import json; data=json.load(open('data/backgrounds/background_inventory.json')); print(f'Total backgrounds: {len(data)}')"
```

#### Phase 2: Build Defect Template Library

```bash
python scripts/build_defect_templates.py \
    --roi_metadata data/processed/roi_patches/roi_metadata.csv \
    --output_dir data/defect_templates \
    --min_suitability 0.7
```

**Expected duration**: 1-2 minutes
**Expected output**: Template metadata with ~1,000-3,000 defect templates

**Verification**:
```bash
python -c "import json; data=json.load(open('data/defect_templates/templates_metadata.json')); print(f'Total templates: {len(data)}')"
```

#### Phase 3: Generate Augmented Data (CORE)

```bash
python scripts/generate_augmented_data.py \
    --model_path outputs/controlnet_training/best.pth \
    --backgrounds_dir data/backgrounds \
    --templates_dir data/defect_templates \
    --output_dir data/augmented \
    --num_samples 2500 \
    --samples_per_class '{"1":625,"2":625,"3":625,"4":625}' \
    --scale_min 0.8 \
    --scale_max 1.0 \
    --device cuda \
    --batch_size 4 \
    --save_hints
```

**Expected duration**: 30-60 minutes (GPU-dependent)
**Expected output**: 2,500 augmented image-mask pairs

**Verification**:
```bash
ls data/augmented/images/ | wc -l  # Should show 2500
ls data/augmented/masks/ | wc -l   # Should show 2500
```

#### Phase 4: Validate Augmented Quality

```bash
python scripts/validate_augmented_quality.py \
    --augmented_dir data/augmented \
    --output_dir data/augmented/validation \
    --min_quality_score 0.7 \
    --check_blur \
    --check_artifacts \
    --check_color \
    --check_defect_consistency \
    --check_defect_presence
```

**Expected duration**: 5-10 minutes
**Expected pass rate**: 70-85% (1,750-2,125 samples)

**Verification**:
```bash
cat data/augmented/validation/validation_statistics.json
```

#### Phase 5: Merge Datasets

```bash
python scripts/merge_datasets.py \
    --original_csv train.csv \
    --original_images train_images \
    --augmented_dir data/augmented \
    --output_csv data/final_dataset/train_augmented.csv \
    --output_dir data/final_dataset \
    --use_only_passed
```

**Expected duration**: 5-10 minutes
**Expected output**: train_augmented.csv with 14,318-14,693 total samples

**Verification**:
```bash
wc -l data/final_dataset/train_augmented.csv
# Should show: ~14,319-14,694 lines (including header)

cat data/final_dataset/dataset_statistics.txt
```

---

## Parameter Reference

### extract_clean_backgrounds.py

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--train_csv` | str | required | Path to train.csv |
| `--image_dir` | str | required | Path to train_images/ |
| `--output_dir` | str | required | Output directory for backgrounds |
| `--patch_size` | int | 512 | Size of extracted patches (512×512) |
| `--patches_per_image` | int | 5 | Max patches per image |
| `--min_quality` | float | 0.7 | Minimum quality threshold (0-1) |
| `--stride` | int | 256 | Sliding window stride |
| `--min_defect_free_ratio` | float | 0.95 | Min ratio of defect-free pixels |

### build_defect_templates.py

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--roi_metadata` | str | required | Path to roi_metadata.csv |
| `--output_dir` | str | required | Output directory for templates |
| `--min_suitability` | float | 0.7 | Min suitability score for matching |

### generate_augmented_data.py

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--model_path` | str | required | Path to trained ControlNet model |
| `--backgrounds_dir` | str | required | Path to backgrounds directory |
| `--templates_dir` | str | required | Path to defect templates |
| `--output_dir` | str | required | Output directory for augmented data |
| `--num_samples` | int | 2500 | Total samples to generate |
| `--samples_per_class` | json | balanced | Samples per class (JSON dict) |
| `--scale_min` | float | 0.8 | Min defect size scale factor |
| `--scale_max` | float | 1.0 | Max defect size scale factor |
| `--device` | str | cuda | Device (cuda/cpu) |
| `--batch_size` | int | 4 | Batch size for inference |
| `--save_hints` | flag | False | Save multi-channel hints |
| `--seed` | int | 42 | Random seed for reproducibility |

### validate_augmented_quality.py

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--augmented_dir` | str | required | Path to augmented data |
| `--output_dir` | str | required | Output directory for validation |
| `--min_quality_score` | float | 0.7 | Min overall quality score (0-1) |
| `--check_blur` | flag | True | Enable blur detection |
| `--check_artifacts` | flag | True | Enable artifact detection |
| `--check_color` | flag | True | Enable color consistency check |
| `--check_defect_consistency` | flag | True | Enable defect metrics check |
| `--check_defect_presence` | flag | True | Enable defect presence check |

**Quality Score Weights**:
- Blur: 20%
- Artifacts: 20%
- Color consistency: 15%
- Defect consistency: 25%
- Defect presence: 20%

### merge_datasets.py

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--original_csv` | str | required | Path to original train.csv |
| `--original_images` | str | required | Path to train_images/ |
| `--augmented_dir` | str | required | Path to augmented data |
| `--output_csv` | str | required | Output path for merged CSV |
| `--output_dir` | str | required | Output directory for statistics |
| `--use_only_passed` | flag | False | Use only validation-passed samples |

---

## Output Structure

### Complete Directory Tree

```
data/
├── backgrounds/
│   ├── smooth/
│   │   ├── bg_00000.jpg
│   │   ├── bg_00001.jpg
│   │   └── ...
│   ├── vertical_stripe/
│   ├── horizontal_stripe/
│   ├── textured/
│   ├── complex_pattern/
│   └── background_inventory.json
│
├── defect_templates/
│   ├── templates_metadata.json
│   ├── template_statistics.json
│   └── matching_rules.json
│
├── augmented/
│   ├── images/
│   │   ├── aug_00000.jpg
│   │   ├── aug_00001.jpg
│   │   └── ... (2500 files)
│   ├── masks/
│   │   ├── aug_00000.png
│   │   ├── aug_00001.png
│   │   └── ... (2500 files)
│   ├── hints/ (optional)
│   │   ├── aug_00000.png
│   │   └── ...
│   ├── augmented_metadata.json
│   ├── generation_log.txt
│   └── validation/
│       ├── quality_scores.json
│       ├── passed_samples.txt
│       ├── rejected_samples.txt
│       ├── validation_statistics.json
│       └── quality_report.txt
│
└── final_dataset/
    ├── train_augmented.csv
    ├── dataset_statistics.json
    └── dataset_statistics.txt
```

### Key Output Files

#### background_inventory.json
```json
[
  {
    "background_id": "bg_00000",
    "source_image": "00a0f53fb.jpg",
    "background_type": "vertical_stripe",
    "patch_location": [100, 50],
    "quality_score": 0.85,
    "quality_metrics": {
      "blur_score": 0.88,
      "contrast_score": 0.82,
      "brightness_score": 0.75,
      "noise_score": 0.95
    }
  }
]
```

#### templates_metadata.json
```json
{
  "template_00000": {
    "roi_id": "roi_00123",
    "class_id": 1,
    "defect_subtype": "linear_scratch",
    "background_type": "vertical_stripe",
    "compatible_backgrounds": ["vertical_stripe", "horizontal_stripe"],
    "defect_metrics": {
      "width": 45,
      "height": 180,
      "aspect_ratio": 4.0,
      "linearity": 0.92,
      "solidity": 0.75
    }
  }
}
```

#### augmented_metadata.json
```json
[
  {
    "aug_id": "aug_00000",
    "image_file": "aug_00000.jpg",
    "mask_file": "aug_00000.png",
    "class_id": 1,
    "background_id": "bg_00123",
    "template_id": "template_00045",
    "background_type": "vertical_stripe",
    "defect_subtype": "linear_scratch",
    "scale_factor": 0.92,
    "defect_position": [150, 200],
    "generation_timestamp": "2026-02-09T10:30:15"
  }
]
```

#### train_augmented.csv
```csv
ImageId,ClassId,EncodedPixels
00a0f53fb.jpg,1,1 2 3 4 ...
00a0f53fb.jpg,2,
aug_00000.jpg,1,10 5 15 3 ...
aug_00001.jpg,2,20 8 25 6 ...
```

---

## Quality Control

### Quality Validation Checks

#### 1. Blur Detection (20% weight)
- **Method**: Laplacian variance
- **Threshold**: >100 (sharp), <50 (blurry)
- **Score**: `min(variance / 200, 1.0)`

#### 2. Artifact Detection (20% weight)
- **Method**: Gradient magnitude analysis
- **Threshold**: 95th percentile < 150
- **Detects**: Abnormal edges, halos, noise patterns

#### 3. Color Consistency (15% weight)
- **Method**: LAB color space statistics
- **Checks**: Luminance stability, color range
- **Flags**: Unusual color shifts, saturation issues

#### 4. Defect Metrics Consistency (25% weight)
- **Method**: Re-analyze generated defect metrics
- **Comparison**: Expected subtype vs actual metrics
- **Thresholds**:
  - Linear scratch: linearity > 0.7
  - Compact blob: solidity > 0.7
  - Elongated: aspect_ratio > 2.0

#### 5. Defect Presence (20% weight)
- **Method**: Mask area analysis
- **Range**: 0.1% - 30% of image area
- **Flags**: Too small (invisible) or too large (unrealistic)

### Quality Score Interpretation

| Score Range | Quality Level | Action |
|-------------|---------------|--------|
| 0.9 - 1.0 | Excellent | Use directly |
| 0.7 - 0.9 | Good | Use (default threshold) |
| 0.5 - 0.7 | Marginal | Review manually |
| 0.0 - 0.5 | Poor | Reject |

### Adjusting Quality Threshold

If pass rate is too low (<60%):
```bash
# Option 1: Lower threshold
python scripts/validate_augmented_quality.py \
    --min_quality_score 0.6  # Instead of 0.7

# Option 2: Disable specific checks
python scripts/validate_augmented_quality.py \
    --no-check_color  # Skip color consistency
```

If pass rate is too high (>95%):
```bash
# Option 1: Raise threshold
python scripts/validate_augmented_quality.py \
    --min_quality_score 0.8

# Option 2: Enable stricter checks
python scripts/validate_augmented_quality.py \
    --strict_mode
```

---

## Troubleshooting

### Common Issues

#### Issue 1: "CUDA out of memory"

**Symptoms**:
```
RuntimeError: CUDA out of memory. Tried to allocate X MiB
```

**Solutions**:
```bash
# Solution 1: Reduce batch size
python scripts/generate_augmented_data.py --batch_size 2  # Default: 4

# Solution 2: Use CPU (slower)
python scripts/generate_augmented_data.py --device cpu

# Solution 3: Generate in stages
python scripts/generate_augmented_data.py --num_samples 1000
# Then run again with different output dir
```

#### Issue 2: "No compatible background-defect pairs found"

**Symptoms**:
```
Error: Could not find compatible background for template_id=XXX after 100 attempts
```

**Root cause**: Overly restrictive matching rules or insufficient background diversity

**Solutions**:
```bash
# Solution 1: Lower suitability threshold
python scripts/build_defect_templates.py --min_suitability 0.5  # Default: 0.7

# Solution 2: Extract more backgrounds
python scripts/extract_clean_backgrounds.py --patches_per_image 10  # Default: 5

# Solution 3: Lower background quality threshold
python scripts/extract_clean_backgrounds.py --min_quality 0.5  # Default: 0.7
```

#### Issue 3: Low validation pass rate (<60%)

**Symptoms**:
```
Validation Statistics:
  Total samples: 2500
  Passed: 1200 (48%)
  Rejected: 1300 (52%)
```

**Solutions**:
```bash
# Solution 1: Analyze rejection reasons
cat data/augmented/validation/quality_report.txt | grep "Rejection reasons"

# Solution 2: Adjust quality threshold
python scripts/validate_augmented_quality.py --min_quality_score 0.6

# Solution 3: Improve ControlNet training
# Retrain with more epochs or better hyperparameters
```

#### Issue 4: "RLE encoding error"

**Symptoms**:
```
ValueError: Invalid RLE format
```

**Solutions**:
```bash
# Solution 1: Check mask format
python -c "from PIL import Image; img=Image.open('data/augmented/masks/aug_00000.png'); print(img.mode, img.size)"
# Expected: L (grayscale), (1600, 256)

# Solution 2: Verify RLE utility
python -c "from src.utils.rle import mask_to_rle; import numpy as np; rle=mask_to_rle(np.zeros((256,1600))); print(rle)"
```

#### Issue 5: Slow generation (<10 samples/minute)

**Solutions**:
```bash
# Solution 1: Verify GPU usage
nvidia-smi  # Check GPU utilization should be >80%

# Solution 2: Increase batch size (if memory allows)
python scripts/generate_augmented_data.py --batch_size 8  # Default: 4

# Solution 3: Disable hint saving
python scripts/generate_augmented_data.py  # Remove --save_hints flag
```

### Logging and Debugging

#### Enable verbose logging:
```bash
python scripts/generate_augmented_data.py --verbose
```

#### Check generation log:
```bash
cat data/augmented/generation_log.txt
```

#### Visualize samples for debugging:
```bash
python scripts/visualize_augmented_samples.py \
    --augmented_dir data/augmented \
    --num_samples 20 \
    --output_dir debug_visualizations
```

---

## Performance Benchmarks

### Expected Execution Times

**System specs**: RTX 3060 (12GB VRAM), 16GB RAM, i7 CPU

| Phase | Duration | GPU Usage | Output Size |
|-------|----------|-----------|-------------|
| Phase 1: Background Extraction | 10-20 min | 0% | ~1-2 GB |
| Phase 2: Template Library | 1-2 min | 0% | <10 MB |
| Phase 3: Data Generation | 30-60 min | 80-95% | ~2-4 GB |
| Phase 4: Quality Validation | 5-10 min | 0% | <50 MB |
| Phase 5: Dataset Merger | 5-10 min | 0% | ~100 MB |
| **Total** | **51-103 min** | - | **~3-6 GB** |

### Throughput Metrics

- **Background extraction**: ~10-20 images/sec
- **Data generation**: ~0.7-1.5 samples/sec (GPU-dependent)
- **Quality validation**: ~4-8 samples/sec
- **Dataset merger**: ~200-400 samples/sec (RLE encoding)

### Optimization Tips

1. **Use SSD storage**: 2-3× faster I/O for image loading
2. **Increase batch size**: Linear speedup until memory limit
3. **Parallel background extraction**: Use `--num_workers` if implemented
4. **Cache hint generation**: Reuse hints for similar backgrounds
5. **Skip hint saving**: Saves ~30% disk I/O time

---

## Advanced Configuration

### Custom Defect Size Distribution

Instead of uniform 80-100% scaling, use custom distribution:

```python
# In generate_augmented_data.py, modify scale_factor sampling:
# Replace:
scale_factor = random.uniform(args.scale_min, args.scale_max)

# With:
scale_factor = np.random.beta(a=5, b=2) * 0.2 + 0.8  # Peak at 90%
```

### Custom Class Distribution

For imbalanced augmentation:

```bash
python scripts/generate_augmented_data.py \
    --samples_per_class '{"1":800,"2":600,"3":600,"4":500}'
```

### Multi-GPU Generation

Split generation across GPUs:

```bash
# Terminal 1 (GPU 0)
CUDA_VISIBLE_DEVICES=0 python scripts/generate_augmented_data.py \
    --num_samples 1250 --output_dir data/augmented_gpu0

# Terminal 2 (GPU 1)
CUDA_VISIBLE_DEVICES=1 python scripts/generate_augmented_data.py \
    --num_samples 1250 --output_dir data/augmented_gpu1

# Merge outputs
python scripts/merge_augmented_outputs.py \
    --input_dirs data/augmented_gpu0 data/augmented_gpu1 \
    --output_dir data/augmented
```

### Custom Matching Rules

Edit `data/defect_templates/matching_rules.json`:

```json
{
  "linear_scratch": {
    "compatible_backgrounds": ["vertical_stripe", "horizontal_stripe"],
    "min_suitability": 0.8  # Stricter matching
  },
  "compact_blob": {
    "compatible_backgrounds": ["smooth", "textured"],
    "min_suitability": 0.6  # More lenient
  }
}
```

### Integration with Training Pipeline

After augmentation, use in training:

```python
import pandas as pd

# Load augmented dataset
df = pd.read_csv('data/final_dataset/train_augmented.csv')

# Create dataset (standard PyTorch Dataset)
from torch.utils.data import Dataset

class SteelDefectDataset(Dataset):
    def __init__(self, df, image_dirs):
        self.df = df
        self.image_dirs = image_dirs  # ['train_images', 'data/augmented/images']
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image_id = row['ImageId']
        
        # Try loading from original, then augmented
        for img_dir in self.image_dirs:
            img_path = os.path.join(img_dir, image_id)
            if os.path.exists(img_path):
                image = load_image(img_path)
                break
        
        # Decode RLE mask
        mask = rle_to_mask(row['EncodedPixels'], (256, 1600))
        return image, mask
```

---

## Appendix

### File Format Specifications

#### Image Format
- **Type**: JPEG
- **Size**: 1600×256 pixels (W×H)
- **Color**: RGB (3 channels)
- **Bit depth**: 8-bit per channel

#### Mask Format
- **Type**: PNG
- **Size**: 1600×256 pixels (W×H)
- **Color**: Grayscale (1 channel)
- **Values**: 0 (background), 255 (defect)

#### RLE Format
- **Encoding**: Run-length encoding (pixel_start, run_length, ...)
- **Indexing**: Column-major order (top-to-bottom, left-to-right)
- **Example**: `"1 2 10 5"` = pixels [1,2] and [10,11,12,13,14]

### Background Type Definitions

| Type | Description | Characteristics |
|------|-------------|-----------------|
| `smooth` | Uniform texture | Low variance, minimal patterns |
| `vertical_stripe` | Vertical lines/stripes | Strong vertical edges |
| `horizontal_stripe` | Horizontal lines/stripes | Strong horizontal edges |
| `textured` | Complex texture | High local variance |
| `complex_pattern` | Mixed patterns | Multiple pattern types |

### Defect Subtype Definitions

| Subtype | Characteristics | Typical Metrics |
|---------|-----------------|-----------------|
| `linear_scratch` | Long, thin scratches | linearity>0.7, aspect_ratio>3 |
| `elongated` | Stretched defects | aspect_ratio>2, linearity<0.7 |
| `compact_blob` | Circular/round defects | solidity>0.7, aspect_ratio<2 |
| `irregular` | Complex shapes | Low solidity, varied metrics |
| `general` | Default category | Moderate metrics |

### Contact and Support

For issues or questions:
- **GitHub Issues**: [Project Repository](https://github.com/yourusername/severstal-steel-defect-detection)
- **Documentation**: This file (AUGMENTATION_PIPELINE_GUIDE.md)
- **Email**: your.email@example.com

### License

This augmentation pipeline is part of the Severstal Steel Defect Detection project.

### Changelog

- **v1.0** (2026-02-09): Initial pipeline implementation
  - 5-phase augmentation system
  - ControlNet-based generation
  - Multi-stage quality validation
  - Seamless dataset integration

---

## Quick Reference Commands

```bash
# Full pipeline (automated)
python scripts/run_augmentation_pipeline.py --train_csv train.csv --image_dir train_images --model_path outputs/controlnet_training/best.pth

# Individual phases
python scripts/extract_clean_backgrounds.py --train_csv train.csv --image_dir train_images --output_dir data/backgrounds
python scripts/build_defect_templates.py --roi_metadata data/processed/roi_patches/roi_metadata.csv --output_dir data/defect_templates
python scripts/generate_augmented_data.py --model_path outputs/controlnet_training/best.pth --backgrounds_dir data/backgrounds --templates_dir data/defect_templates --output_dir data/augmented
python scripts/validate_augmented_quality.py --augmented_dir data/augmented --output_dir data/augmented/validation
python scripts/merge_datasets.py --original_csv train.csv --augmented_dir data/augmented --output_csv data/final_dataset/train_augmented.csv

# Verification
ls data/backgrounds/ | wc -l
ls data/augmented/images/ | wc -l
cat data/augmented/validation/validation_statistics.json
wc -l data/final_dataset/train_augmented.csv
```
